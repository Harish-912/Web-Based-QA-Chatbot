{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ce67ebb",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04929904",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langchain_core.messages import HumanMessage, AIMessage, BaseMessage\n",
    "from typing import TypedDict, Annotated, List\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain.memory import ChatMessageHistory\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416aab61",
   "metadata": {},
   "source": [
    "### Load API Keys and Enable Langsmith tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61f52afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Chatbot_with_RAG_and_Langraph\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bbf7d42",
   "metadata": {},
   "source": [
    "### Initialize Gemini LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004bcfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",  # or gemini-pro if you want\n",
    "    google_api_key=google_api_key,\n",
    "    temperature=0.3,\n",
    "    top_k=4\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8973a21",
   "metadata": {},
   "source": [
    "### Load embedding model and setup retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "039f6d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=hf_api_key,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(\"../vectorstores/dxfactor\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a37b584",
   "metadata": {},
   "source": [
    "### Build Chatbot with Langraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a40951d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65cde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatState(TypedDict, total=False):  # <-- `total=False` makes all fields optional\n",
    "    chat_history: Annotated[List[BaseMessage], \"chat_history\"]\n",
    "    retrieved_context: Annotated[str, \"retrieved_context\"]\n",
    "    \n",
    "def retrieve(state: ChatState) -> ChatState:\n",
    "    pprint.pprint(state)\n",
    "\n",
    "    messages = state.get(\"chat_history\", [])\n",
    "\n",
    "    user_msg = messages.content[-1]\n",
    "    docs = retriever.invoke(user_msg)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    return {\"chat_history\": messages, \"retrieved_context\": context}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c71d34ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve({\"chat_history\": HumanMessage(content=[\"What is the revenue in Q2?\"])})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba74ca8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_node(state: ChatState) -> ChatState:\n",
    "    pprint.pprint(state)\n",
    "    state[\"chat_history\"] = HumanMessage(content=[\"What is the revenue in Q2?\"])\n",
    "    return state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4172a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------\n",
    "# Define state shape\n",
    "# ---------------------\n",
    "class ChatState(TypedDict):  # <- total=False to make optional fields ok\n",
    "    input: HumanMessage\n",
    "    chat_history: Annotated[List[BaseMessage], 'chat_history']\n",
    "    output: AIMessage\n",
    "    retrieved_context: str\n",
    "\n",
    "def start_node(state: ChatState) -> ChatState:\n",
    "    pprint.pprint(state)\n",
    "    return state\n",
    "\n",
    "# --------------------------\n",
    "# Define retriever node\n",
    "# --------------------------\n",
    "def retrieve(state: ChatState) -> ChatState:\n",
    "    pprint.pprint(state)\n",
    "\n",
    "    messages = state.get(\"chat_history\", [])\n",
    "    user_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]\n",
    "    user_msg = user_messages.content[-1] if user_messages else \"\"\n",
    "\n",
    "    docs = retriever.invoke(user_msg)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "    return {\n",
    "        \"chat_history\": messages,\n",
    "        \"retrieved_context\": context\n",
    "    }\n",
    "\n",
    "# -------------------------\n",
    "# Define generate node\n",
    "# -------------------------\n",
    "def generate(state: ChatState) -> ChatState:\n",
    "    messages = state.get(\"chat_history\", [])\n",
    "    context = state.get(\"retrieved_context\", \"\")\n",
    "\n",
    "    # Safely get latest human message\n",
    "    user_messages = [msg for msg in messages if isinstance(msg, HumanMessage)]\n",
    "    user_question = user_messages[-1].content if user_messages else \"\"\n",
    "\n",
    "    prompt = f\"\"\"Answer the user's question using ONLY the following context. \n",
    "If the answer is not in the context, say you don't know.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {user_question}\n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    ai_msg = AIMessage(content=response.content)\n",
    "\n",
    "    print(response.content)\n",
    "\n",
    "    return {\n",
    "        \"chat_history\": messages + [ai_msg],\n",
    "        \"retrieved_context\": context,\n",
    "        \"output\": ai_msg\n",
    "    }\n",
    "\n",
    "# ---------------------------\n",
    "# Build the LangGraph\n",
    "# ---------------------------\n",
    "builder = StateGraph(ChatState)\n",
    "builder.add_node(\"start\", start_node)\n",
    "builder.add_node(\"retrieve\", retrieve)\n",
    "builder.add_node(\"generate\", generate)\n",
    "\n",
    "builder.set_entry_point(\"start\")\n",
    "builder.add_edge(\"start\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"generate\")\n",
    "builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# ------------------------------------------\n",
    "# Add memory with RunnableWithMessageHistory\n",
    "# ------------------------------------------\n",
    "# Memory store to keep track of chat sessions\n",
    "memory_store = {}\n",
    "\n",
    "def get_memory(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in memory_store:\n",
    "        memory_store[session_id] = ChatMessageHistory()\n",
    "    return memory_store[session_id]\n",
    "\n",
    "# Creating the graph with memory handling\n",
    "graph_with_history = RunnableWithMessageHistory(\n",
    "    graph,\n",
    "    get_session_history=get_memory,\n",
    "    input_messages_key=\"input\",  # You'll pass the user message here\n",
    "    history_messages_key=\"chat_history\"  # This is used by the state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "3b430797",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [],\n",
      " 'input': HumanMessage(content=['Why use dxfactor?'], additional_kwargs={}, response_metadata={})}\n",
      "{'chat_history': [],\n",
      " 'input': HumanMessage(content=['Why use dxfactor?'], additional_kwargs={}, response_metadata={})}\n",
      "I don't know.\n",
      "{'input': HumanMessage(content=['Why use dxfactor?'], additional_kwargs={}, response_metadata={}), 'chat_history': [AIMessage(content=\"I don't know.\", additional_kwargs={}, response_metadata={})], 'output': AIMessage(content=\"I don't know.\", additional_kwargs={}, response_metadata={}), 'retrieved_context': '3.4 Enforcement.We reserve the right (but have no obligation) to review, refuse and/or remove any User Content in our sole discretion, and to investigate and/or take appropriate action against you in our sole discretion if you violate the Acceptable Use Policy or any other provision of these Terms or otherwise create liability for us or any other person. Such action may include removing or modifying your User Content, terminating your Account in accordance with Section 8, and/or reporting you to law enforcement authorities.\\n5.1Third-Party Links & Ads.The Site may contain links to third-party websites and services, and/or display advertisements for third parties (collectively, “Third-Party Links & Ads”).\\xa0 Such Third-Party Links & Ads are not under the control of Company, and Company is not responsible for any Third-Party Links & Ads.\\xa0 Company provides access to these Third-Party Links & Ads only as a convenience to you, and does not review, approve, monitor, endorse, warrant, or make any representations with respect to Third-Party Links & Ads.\\xa0 You use all Third-Party Links & Ads at your own risk, and should apply a suitable level of caution and discretion in doing so. When you click on any of the Third-Party Links & Ads, the applicable third party’s terms and policies apply, including the third party’s privacy and data gathering practices.\\xa0 You should make whatever investigation you feel necessary or appropriate before proceeding with any transaction in connection with such Third-Party Links & Ads.\\n\\nDelivering Cutting EdgeAR/VR Solutionsto Meet Your Unique Challenges\\nWHAT WE DELIVER\\nAugmented Reality App Development\\nOur expert developers ignite your customer experience by using your business data to develop custom, personalized augmented reality applications. Meet the growing customer needs and tackle all the upcoming challenges with state-of-the-art AR applications.\\nVirtual Reality App Development\\nOur core VR solutions include:\\nBecome outcome obsessed\\nWhether you need to steady the ship, build a new one or revolutionize your business, we can help you to get the best results.\\ninquiry@dxfactor.com\\nCompany\\nSolutions\\nResources\\nCertification\\nmagic_popup_12\\n\\n========== How We Engage ==========\\nURL: https://dxfactor.com/how-we-engage/\\n\\n3.3 Acceptable Use Policy.The following terms constitute our “Acceptable Use Policy”:\\n(a) You agree not to use the Site to collect, upload, transmit, display, or distribute any User Content (i) that violates any third-party right, including any copyright, trademark, patent, trade secret, moral right, privacy right, right of publicity, or any other intellectual property or proprietary right, (ii) that is unlawful, harassing, abusive, tortious, threatening, harmful, invasive of another’s privacy, vulgar, defamatory, false, intentionally misleading, trade libelous, pornographic, obscene, patently offensive, promotes racism, bigotry, hatred, or physical harm of any kind against any group or individual or is otherwise objectionable, (iii) that is harmful to minors in any way, or (iv) that is in violation of any law, regulation, or obligations or restrictions imposed by any third party.'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = graph_with_history.invoke(\n",
    "    input={\"input\": HumanMessage(content=[\"Why use dxfactor?\"])},\n",
    "    config={\"configurable\": {\"session_id\": \"user-123\"}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19f53717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import StateGraph, END\n",
    "from langchain_core.runnables import Runnable\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "# Define state schema (chat_history is managed by RunnableWithMessageHistory)\n",
    "from typing import TypedDict, List, Union\n",
    "\n",
    "class ChatState(TypedDict):\n",
    "    input: HumanMessage\n",
    "    chat_history: List[Union[HumanMessage, AIMessage]]\n",
    "    output: AIMessage\n",
    "\n",
    "# Chat function using your llm (already initialized)\n",
    "def chat_node(state: ChatState) -> ChatState:\n",
    "    user_msg = state[\"input\"]\n",
    "    chat_history = state[\"chat_history\"]\n",
    "    # Get the response from the LLM\n",
    "    response = llm.invoke(chat_history + [user_msg])\n",
    "    return {\n",
    "        \"input\": user_msg,\n",
    "        \"chat_history\": chat_history + [user_msg, response],\n",
    "        \"output\": response  # this is key!\n",
    "    }\n",
    "\n",
    "# Build the graph\n",
    "builder = StateGraph(ChatState)\n",
    "builder.add_node(\"chat\", chat_node)\n",
    "builder.set_entry_point(\"chat\")\n",
    "builder.add_edge(\"chat\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "memory_store = {}\n",
    "\n",
    "def get_memory(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in memory_store:\n",
    "        memory_store[session_id] = ChatMessageHistory()\n",
    "    pprint.pprint(memory_store)\n",
    "    return memory_store[session_id]\n",
    "\n",
    "# Creating the graph with memory handling\n",
    "graph_with_history = RunnableWithMessageHistory(\n",
    "    graph,\n",
    "    get_session_history=get_memory,\n",
    "    input_messages_key=\"input\",  # You'll pass the user message here\n",
    "    history_messages_key=\"chat_history\"  # This is used by the state\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9e6e9aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user-123': InMemoryChatMessageHistory(messages=[])}\n",
      "{'input': HumanMessage(content=['What is the revenue in Q2?'], additional_kwargs={}, response_metadata={}), 'chat_history': [HumanMessage(content=['What is the revenue in Q2?'], additional_kwargs={}, response_metadata={}), AIMessage(content=\"I am unable to access real-time information, including financial data like quarterly revenue. To find the revenue for Q2, you would need to consult a reliable source such as:\\n\\n*   **The company's official investor relations website:** Look for press releases, quarterly reports, or financial statements.\\n*   **Financial news websites:** Reputable sources like Reuters, Bloomberg, or the Wall Street Journal often report on company earnings.\\n*   **Financial data providers:** Services like FactSet or Refinitiv provide detailed financial data.\\n\\nWhen searching, be sure to specify the company you are interested in and the year for which you want the Q2 revenue.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run-8eb0a3b1-cfe7-4b9e-b211-cf3a967d6bab-0', usage_metadata={'input_tokens': 8, 'output_tokens': 134, 'total_tokens': 142, 'input_token_details': {'cache_read': 0}})], 'output': AIMessage(content=\"I am unable to access real-time information, including financial data like quarterly revenue. To find the revenue for Q2, you would need to consult a reliable source such as:\\n\\n*   **The company's official investor relations website:** Look for press releases, quarterly reports, or financial statements.\\n*   **Financial news websites:** Reputable sources like Reuters, Bloomberg, or the Wall Street Journal often report on company earnings.\\n*   **Financial data providers:** Services like FactSet or Refinitiv provide detailed financial data.\\n\\nWhen searching, be sure to specify the company you are interested in and the year for which you want the Q2 revenue.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run-8eb0a3b1-cfe7-4b9e-b211-cf3a967d6bab-0', usage_metadata={'input_tokens': 8, 'output_tokens': 134, 'total_tokens': 142, 'input_token_details': {'cache_read': 0}})}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "response = graph_with_history.invoke(\n",
    "    input={\"input\": HumanMessage(content=[\"What is the revenue in Q2?\"])},\n",
    "    config={\"configurable\": {\"session_id\": \"user-123\"}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "af6555d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'user-123': InMemoryChatMessageHistory(messages=[HumanMessage(content=['What is the revenue in Q2?'], additional_kwargs={}, response_metadata={}), AIMessage(content=\"I am unable to access real-time information, including financial data like quarterly revenue. To find the revenue for Q2, you would need to consult a reliable source such as:\\n\\n*   **The company's official investor relations website:** Look for press releases, quarterly reports, or financial statements.\\n*   **Financial news websites:** Reputable sources like Reuters, Bloomberg, or the Wall Street Journal often report on company earnings.\\n*   **Financial data providers:** Services like FactSet or Refinitiv provide detailed financial data.\\n\\nWhen searching, be sure to specify the company you are interested in and the year for which you want the Q2 revenue.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run-8eb0a3b1-cfe7-4b9e-b211-cf3a967d6bab-0', usage_metadata={'input_tokens': 8, 'output_tokens': 134, 'total_tokens': 142, 'input_token_details': {'cache_read': 0}})])}\n",
      "{'input': HumanMessage(content=[\"Ok, that's not a problem.\"], additional_kwargs={}, response_metadata={}), 'chat_history': [HumanMessage(content=['What is the revenue in Q2?'], additional_kwargs={}, response_metadata={}), AIMessage(content=\"I am unable to access real-time information, including financial data like quarterly revenue. To find the revenue for Q2, you would need to consult a reliable source such as:\\n\\n*   **The company's official investor relations website:** Look for press releases, quarterly reports, or financial statements.\\n*   **Financial news websites:** Reputable sources like Reuters, Bloomberg, or the Wall Street Journal often report on company earnings.\\n*   **Financial data providers:** Services like FactSet or Refinitiv provide detailed financial data.\\n\\nWhen searching, be sure to specify the company you are interested in and the year for which you want the Q2 revenue.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run-8eb0a3b1-cfe7-4b9e-b211-cf3a967d6bab-0', usage_metadata={'input_tokens': 8, 'output_tokens': 134, 'total_tokens': 142, 'input_token_details': {'cache_read': 0}}), HumanMessage(content=[\"Ok, that's not a problem.\"], additional_kwargs={}, response_metadata={}), AIMessage(content=\"Great! I'm glad I could help clarify how to find the information. Let me know if you have any other questions.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run-496949d3-1592-40a9-bfdf-2046f79a207a-0', usage_metadata={'input_tokens': 151, 'output_tokens': 27, 'total_tokens': 178, 'input_token_details': {'cache_read': 0}})], 'output': AIMessage(content=\"Great! I'm glad I could help clarify how to find the information. Let me know if you have any other questions.\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-lite', 'safety_ratings': []}, id='run-496949d3-1592-40a9-bfdf-2046f79a207a-0', usage_metadata={'input_tokens': 151, 'output_tokens': 27, 'total_tokens': 178, 'input_token_details': {'cache_read': 0}})}\n"
     ]
    }
   ],
   "source": [
    "response = graph_with_history.invoke(\n",
    "    input={\"input\": HumanMessage(content=[\"Ok, that's not a problem.\"])},\n",
    "    config={\"configurable\": {\"session_id\": \"user-123\"}}\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4502da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321d9025",
   "metadata": {},
   "source": [
    "### Running Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4461656",
   "metadata": {},
   "outputs": [],
   "source": [
    "session_id = \"user1\"\n",
    "\n",
    "# Initial empty message list to start the chat\n",
    "chat_history = []\n",
    "\n",
    "print(\"📢 LangGraph Chatbot initialized. Type your question.\")\n",
    "print(\"💡 Type 'quit', 'exit', or 'q' to end the conversation.\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(\"You: \")\n",
    "\n",
    "    if user_input.lower() in {\"quit\", \"exit\", \"q\"}:\n",
    "        print(\"👋 Chat ended.\")\n",
    "        break\n",
    "\n",
    "    # Wrap user input as a HumanMessage\n",
    "    chat_history.append(HumanMessage(content=user_input))\n",
    "\n",
    "    # Invoke the chatbot with chat history\n",
    "    result = graph_with_history.invoke(\n",
    "        {\"messages\": chat_history, \"context\": \"\"},  \n",
    "        config={\"configurable\": {\"session_id\": session_id}}\n",
    "    )\n",
    "\n",
    "    # Get the last message from result and print it\n",
    "    response = result[\"messages\"][-1].content\n",
    "    print(\"Bot:\", response)\n",
    "\n",
    "    # Append bot response to history\n",
    "    chat_history.append(AIMessage(content=response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "8d4ce3cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define state shape\n",
    "class ChatState(TypedDict, total=False):\n",
    "    chat_history: Annotated[List[BaseMessage], \"chat_history\"]\n",
    "    retrieved_context: Annotated[str, \"retrieved_context\"]\n",
    "    output: Annotated[str, \"output\"]  # Ensure output is included in the state\n",
    "\n",
    "\n",
    "# Define start node\n",
    "def start_node(state: ChatState) -> ChatState:\n",
    "    state[\"chat_history\"] = [HumanMessage(content=[\"Hi!\"])]\n",
    "    state[\"output\"] = \"Welcome to the chat!\"  # Provide initial output\n",
    "    return state\n",
    "\n",
    "\n",
    "# Define retrieve node\n",
    "def retrieve(state: ChatState) -> ChatState:\n",
    "    print(state)\n",
    "    messages = state.get(\"chat_history\", [])\n",
    "\n",
    "    if not messages:\n",
    "        raise Exception(\"No chat history found.\")\n",
    "\n",
    "    user_msg = messages[-1].content[0]  # Get last user's message\n",
    "    docs = retriever.invoke(user_msg)\n",
    "    context = \"\\n\\n\".join(doc.page_content for doc in docs) if docs else \"\"\n",
    "\n",
    "    state[\"retrieved_context\"] = context\n",
    "    state[\"output\"] = context if context else \"No relevant context found.\"  # Update output based on retrieved context\n",
    "    return state\n",
    "\n",
    "\n",
    "# Define generate node\n",
    "def generate(state: ChatState) -> ChatState:\n",
    "    messages = state.get(\"chat_history\", [])\n",
    "    context = state.get(\"retrieved_context\", \"\")\n",
    "\n",
    "    if not messages:\n",
    "        raise Exception(\"No chat history found.\")\n",
    "\n",
    "    user_question = messages[-1].content[0]  # Get the content of the last HumanMessage\n",
    "\n",
    "    # Improved prompt with clearer instructions\n",
    "    prompt = f\"\"\"Based on the context provided, answer the user's question as accurately as possible.   \n",
    "If you cannot find an answer based on the context, try suggesting that the user provide more details or rephrase their question.  \n",
    "\n",
    "Context:  \n",
    "{context}  \n",
    "\n",
    "Question: {user_question}  \n",
    "\"\"\"\n",
    "\n",
    "    response = llm.invoke(prompt)\n",
    "    new_message = AIMessage(content=[response.content])\n",
    "\n",
    "    # Append the new AIMessage to the chat history\n",
    "    messages.append(new_message)\n",
    "\n",
    "    # Handling case for \"I don't know.\"\n",
    "    output_message = response.content\n",
    "    if output_message.lower() == \"i don't know.\":\n",
    "        # Suggestion for the user or ask for more information\n",
    "        output_message = \"Unfortunately, I couldn't find an answer. Could you provide more details or ask a different question?\"\n",
    "\n",
    "        # Return the updated state with output\n",
    "    state[\"chat_history\"] = messages\n",
    "    state[\"output\"] = output_message  # Store the AI's response as output\n",
    "\n",
    "    return state\n",
    "\n",
    "# Build the LangGraph\n",
    "builder = StateGraph(ChatState)\n",
    "builder.add_node(\"start\", start_node)\n",
    "builder.add_node(\"retrieve\", retrieve)\n",
    "builder.add_node(\"generate\", generate)\n",
    "\n",
    "builder.set_entry_point(\"start\")\n",
    "builder.add_edge(\"start\", \"retrieve\")\n",
    "builder.add_edge(\"retrieve\", \"generate\")\n",
    "builder.add_edge(\"generate\", END)\n",
    "\n",
    "graph = builder.compile()\n",
    "\n",
    "# Add memory with RunnableWithMessageHistory\n",
    "# Memory store to keep track of chat sessions\n",
    "memory_store = {}\n",
    "\n",
    "\n",
    "def get_memory(session_id: str) -> ChatMessageHistory:\n",
    "    if session_id not in memory_store:\n",
    "        memory_store[session_id] = ChatMessageHistory()\n",
    "    return memory_store[session_id]\n",
    "\n",
    "\n",
    "# Creating the graph with memory handling\n",
    "graph_with_history = RunnableWithMessageHistory(\n",
    "    graph,\n",
    "    get_session_history=get_memory,\n",
    "    input_messages_key=\"input\",  # You'll pass the user message here\n",
    "    history_messages_key=\"chat_history\"  # This is used by the state\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "88e9a47b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chat_history': [HumanMessage(content=['Hi!'], additional_kwargs={}, response_metadata={})], 'output': 'Welcome to the chat!'}\n",
      "{'chat_history': [HumanMessage(content=['Hi!'], additional_kwargs={}, response_metadata={}), AIMessage(content=['Hi! Based on the provided context, I can tell you that DXFactor has the following open positions:\\n\\n*   DXFactor - 9 open roles\\n*   Data Science - 1 open role\\n*   Talent Acquisition / Recruitment - 1 open role\\n\\nYou can contact them at inquiry@dxfactor.com.'], additional_kwargs={}, response_metadata={})], 'retrieved_context': 'Open Positions\\nDXFactor- 9 \\n                  Open roles\\nData Science- 1 \\n                  Open role\\nTalent Acquisition / Recruitment- 1 \\n                  Open role\\ninquiry@dxfactor.com\\nCompany\\nSolutions\\nResources\\nCertification\\nmagic_popup_12\\n\\n========== Fitgenai ==========\\nURL: https://dxfactor.com/fitgenai/\\n\\n========== Contact Us ==========\\nURL: https://dxfactor.com/contact-us/\\n\\nInnovation\\nCreativity and growth hacks through relentless innovation\\nCommitment & Accountability\\nGoing above and beyond with the right attitude, commitment, and excellence\\nEmpathy & Empowerment\\nAn environment where every human THRIVES by empowering and understanding them\\nCAREERS\\nJoin Our Team\\nWe are always looking for top talent and would like to hear from you.Contact us directly or visit our current openings for roles that are suitable for you.\\ninquiry@dxfactor.com\\nCompany\\nSolutions\\nResources\\nCertification\\nmagic_popup_12', 'output': 'Hi! Based on the provided context, I can tell you that DXFactor has the following open positions:\\n\\n*   DXFactor - 9 open roles\\n*   Data Science - 1 open role\\n*   Talent Acquisition / Recruitment - 1 open role\\n\\nYou can contact them at inquiry@dxfactor.com.'}\n"
     ]
    }
   ],
   "source": [
    "### Invoke function\n",
    "response = graph_with_history.invoke(\n",
    "    input={\"input\": HumanMessage(content=[\"What is data engineering\"])},\n",
    "    config={\"configurable\": {\"session_id\": \"user-123\"}}\n",
    ")\n",
    "\n",
    "# Print the response\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
