{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b82eb1",
   "metadata": {},
   "source": [
    "### Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "635b9f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain.chains import create_history_aware_retriever, create_retrieval_chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c23ef0",
   "metadata": {},
   "source": [
    "### Load API Keys and Enable Langsmith tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936a69b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "hf_api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"] = os.getenv(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"Chatbot_with_RAG_and_Webscraping\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e552f45",
   "metadata": {},
   "source": [
    "### Initialize Gemini LLM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2d88dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-2.0-flash-lite', google_api_key=SecretStr('**********'), temperature=0.3, top_k=4, client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x0000021CDF5EBF10>, default_metadata=())"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash-lite\",  # or gemini-pro if you want\n",
    "    google_api_key=google_api_key,\n",
    "    temperature=0.3,\n",
    "    top_k=4\n",
    ")\n",
    "llm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1725c8",
   "metadata": {},
   "source": [
    "### Load embedding model and setup retriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6948678c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['FAISS', 'HuggingFaceInferenceAPIEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x0000021CDC39C410>, search_kwargs={})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model = HuggingFaceInferenceAPIEmbeddings(\n",
    "    api_key=hf_api_key,\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "\n",
    "vectorstore = FAISS.load_local(\"../vectorstores/dxfactor\", embedding_model, allow_dangerous_deserialization=True)\n",
    "\n",
    "retriever = vectorstore.as_retriever()\n",
    "retriever"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b0d9171",
   "metadata": {},
   "source": [
    "### Build Chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993b02dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the RAG Chatbot with Memory!\n",
      "Type 'HISTORY' to view chat history, 'CLEAR' to clear history, or 'STOP' to exit.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hi Harish, I'm doing well, thank you for asking! How can I help you today?\n",
      "(Response time: 1.53 seconds)\n",
      "\n",
      "AI: Based on the context provided, DXFactor is a company focused on digital transformation, particularly in the fitness industry. They seem to be using AI and data-driven solutions to improve member experiences. They have launched FitGenAI, which uses generative AI for member engagement. They also partner with companies like ABC Fitness. You can find more information on their website, dxfactor.com, and their blog.\n",
      "(Response time: 7.52 seconds)\n",
      "\n",
      "AI: I don't have information about the founders of DXfactor in the provided context. However, I can tell you that DXfactor offers solutions related to data analytics, data governance, cloud deployment, and agile delivery. They also have a privacy policy and a contact page on their website. If you'd like to know more about the founders, you could try visiting their website (dxfactor.com) or searching for them online.\n",
      "(Response time: 3.12 seconds)\n",
      "\n",
      "AI: I don't know your name, Harish. I am an AI and do not have access to personal information unless you provide it to me.\n",
      "(Response time: 2.37 seconds)\n",
      "\n",
      "AI: You're right to call me out on that! I apologize. I used \"Harish\" because that's the name you used when you started the conversation. I'm designed to be conversational and helpful, so I try to remember the context of our chat. However, as I am an AI, I don't actually *know* your name or have any memory of past conversations. I only have access to the current conversation. Thanks for pointing out the inconsistency!\n",
      "(Response time: 3.44 seconds)\n",
      "\n",
      "AI: Yes, Harish, I remember that your name is Harish. I'll do my best to keep that in mind as we continue our conversation. How can I help you today?\n",
      "(Response time: 3.45 seconds)\n",
      "\n",
      "AI: Okay, Harish. Based on the context you provided, DXfactor offers Data Engineering Services. They focus on helping businesses leverage their data effectively. Here's a breakdown of what they do:\n",
      "\n",
      "*   **Data Modernization:** They convert your legacy data from older formats to modern ones, working with different databases. This is especially important for organizations with unstructured data like audio, video, and text files.\n",
      "*   **Data Ingestion:** They import data for immediate use or storage in a database, adjusting incoming data for the right formats, structure, and quality.\n",
      "*   **Data Pipelines:** They create systems to transform and move your data between source and target systems based on your business needs. This includes Extract, Transform, and Load (ETL) processes to combine data from various sources into a single, unified source.\n",
      "*   **Data CI/CD:** They use continuous integration and continuous delivery to automate processes and detect code issues, ensuring faster development.\n",
      "*   **Data Lakes and Warehouses:** They build data lakes and warehouses based on your legacy and real-time business data. Data lakes store raw data, while data warehouses structure the data for specific purposes.\n",
      "\n",
      "DXfactor aims to help you get actionable insights from your data in a timely manner, creating smart platforms for scalable growth. They can also help you migrate legacy data to modern databases and cloud-based data lakes or warehouses.\n",
      "(Response time: 9.73 seconds)\n",
      "\n",
      "Chat history has been cleared.\n",
      "\n",
      "AI: I am sorry, but I do not have access to your name. The provided documents do not contain any information about you personally.\n",
      "(Response time: 1.61 seconds)\n",
      "\n",
      "Exiting the chatbot. Goodbye!\n"
     ]
    }
   ],
   "source": [
    "# üß† Memory\n",
    "memory = ConversationBufferWindowMemory(\n",
    "    memory_key=\"chat_history\",\n",
    "    return_messages=True,\n",
    "    k=5,\n",
    ")\n",
    "\n",
    "# üîß Step 1: Create history-aware retriever\n",
    "history_aware_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])\n",
    "\n",
    "history_aware_retriever = create_history_aware_retriever(\n",
    "    llm,\n",
    "    retriever,\n",
    "    history_aware_prompt\n",
    ")\n",
    "\n",
    "# üìù Step 2: Your custom answer prompt\n",
    "answer_prompt = ChatPromptTemplate.from_messages([\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"user\", \"\"\"\n",
    "You are a helpful and conversational assistant.\n",
    "Use the following retrieved context to help answer the user's question, if it's relevant.\n",
    "You may also use information from the chat history to personalize your response.\n",
    "If the answer isn't in the context or history, respond naturally based on your general knowledge ‚Äî but avoid making up facts.\n",
    "\n",
    "Context:\n",
    "{context}\n",
    "\n",
    "Question: {input}\n",
    "\"\"\")\n",
    "])\n",
    "\n",
    "# üõ† Step 3: Build combine_docs_chain manually\n",
    "combine_docs_chain = answer_prompt | llm | StrOutputParser()\n",
    "\n",
    "# üîÑ Step 4: Final RAG chain\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever=history_aware_retriever,\n",
    "    combine_docs_chain=combine_docs_chain\n",
    ")\n",
    "\n",
    "# üîÅ Ask with memory tracking\n",
    "def ask_with_history(user_input):\n",
    "    chat_history = memory.chat_memory.messages\n",
    "    response = rag_chain.invoke({\"input\": user_input, \"chat_history\": chat_history})\n",
    "    memory.chat_memory.add_user_message(user_input)\n",
    "    memory.chat_memory.add_ai_message(response[\"answer\"])\n",
    "    return response[\"answer\"]\n",
    "\n",
    "# üñ• Typing effect\n",
    "def print_typing_effect(text, delay=0.01):\n",
    "    for char in text:\n",
    "        sys.stdout.write(char)\n",
    "        sys.stdout.flush()\n",
    "        time.sleep(delay)\n",
    "    print()\n",
    "\n",
    "def show_history():\n",
    "    print(\"\\n--- Chat History ---\")\n",
    "    for msg in memory.chat_memory.messages:\n",
    "        role = \"User\" if isinstance(msg, HumanMessage) else \"AI\"\n",
    "        print(f\"{role}: {msg.content}\")\n",
    "    print(\"--- End of History ---\\n\")\n",
    "\n",
    "def run_chatbot():\n",
    "    print(\"Welcome to the RAG Chatbot with Memory!\")\n",
    "    print(\"Type 'HISTORY' to view chat history, 'CLEAR' to clear history, or 'STOP' to exit.\\n\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"You: \").strip()\n",
    "\n",
    "        if user_input.upper() in ('STOP', 'EXIT', 'QUIT'):\n",
    "            print(\"Exiting the chatbot. Goodbye!\")\n",
    "            break\n",
    "        elif user_input.upper() == 'HISTORY':\n",
    "            show_history()\n",
    "            continue\n",
    "        elif user_input.upper() == 'CLEAR':\n",
    "            memory.clear()\n",
    "            print(\"Chat history has been cleared.\\n\")\n",
    "            continue\n",
    "\n",
    "        start_time = time.time()\n",
    "        answer = ask_with_history(user_input)\n",
    "        end_time = time.time()\n",
    "\n",
    "        print_typing_effect(f\"AI: {answer}\")\n",
    "        print(f\"(Response time: {end_time - start_time:.2f} seconds)\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "532f639b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20cb78b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
